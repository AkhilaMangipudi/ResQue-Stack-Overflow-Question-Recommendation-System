{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('IR_datasets/cs.stackexchange.com/Posts.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'posts'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#this translator is used to remove the punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def sentencePreProcess(body):\n",
    "    #this removes all the HTML tags\n",
    "    clean_body = BeautifulSoup(body,\"lxml\").text\n",
    "    #this removes all the punctuation\n",
    "    clean_body = clean_body.translate(translator)\n",
    "    #tokenize the given sentence\n",
    "    word_tokens = word_tokenize(clean_body)\n",
    "    #remove the stop words\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    #convert from list to sentence\n",
    "    body = ' '.join(word for word in filtered_sentence)\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCSV(root,quesFileName,ansFileName):\n",
    "    with open(quesFileName,mode='w',encoding='utf-8') as ques_file, open(ansFileName,mode='w',encoding='utf-8') as ans_file:\n",
    "        ques_file = csv.writer(ques_file, delimiter=',')\n",
    "        ans_file = csv.writer(ans_file, delimiter=',')\n",
    "        ques_file.writerow(['Id','Body','AcceptedAnswerId','Score','ViewCount','Title','Tags','AnswerCount','CommentCount','FavoriteCount'])\n",
    "        ans_file.writerow(['Id', 'ParentId','Score','Body','CommentCount'])\n",
    "        for row in root.findall('row'):\n",
    "            post_type_id = row.get(\"PostTypeId\")\n",
    "            if(post_type_id == \"1\"):\n",
    "                #It is a question\n",
    "                post_id = row.get('Id')\n",
    "                body = sentencePreProcess(row.get('Body'))\n",
    "                accepted_answer_id = row.get('AcceptedAnswerId')\n",
    "                score = row.get('Score')\n",
    "                view_count = row.get('ViewCount')\n",
    "                title = sentencePreProcess(row.get('Title'))\n",
    "                tags = sentencePreProcess(row.get('Tags'))\n",
    "                answer_count = row.get('AnswerCount')\n",
    "                comment_count = row.get('CommentCount')\n",
    "                fav_count = row.get('FavoriteCount')\n",
    "                ques_file.writerow([post_id,body,accepted_answer_id,score,view_count,title,tags,answer_count,comment_count,fav_count])\n",
    "            else:\n",
    "                #it is an answer\n",
    "                post_id = row.get('Id')\n",
    "                parent_id = row.get('ParentId')\n",
    "                score = row.get('Score')\n",
    "                body = sentencePreProcess(row.get('Body'))\n",
    "                comment_count = row.get('CommentCount')\n",
    "                ans_file.writerow([post_id,parent_id,score,body,comment_count])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "createCSV(root,\"CS_questions.csv\",\"CS_answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the pre-trained term embeddings\n",
    "import numpy as np\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"hw2_data/glove.6B.50d.txt.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "with open(\"glove.6B.50d.txt\", \"rb\") as lines:\n",
    "    model_word2vec = {line.split()[0]: np.array( list( map(float, line.split( )[1:]) ))\n",
    "           for line in lines}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(\"ir_csv_files/CS_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbedding(body):\n",
    "    output_vec = np.zeros(50)\n",
    "    wordCount = 0\n",
    "    words = body.split()\n",
    "    for word in words:\n",
    "        wordCount = wordCount + 1\n",
    "        if word.encode() in model_word2vec:\n",
    "            output_vec = output_vec + model_word2vec[word.encode()]\n",
    "        else:\n",
    "            output_vec = output_vec + np.zeros(50)\n",
    "    return output_vec/(wordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the questions dataframe is:  (29375, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the questions dataframe is: \",questions_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to get word embeddings of the body part of all the questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the embeddings\n",
    "import numpy as np\n",
    "myarray = np.fromfile('q_body_embeddings.dat', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.29761006e-297 5.75045670e+169 6.52020716e+252 ... 3.75670872e-148\n",
      " 5.73154172e+250 6.87932872e-085]\n"
     ]
    }
   ],
   "source": [
    "print(myarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9039701,)\n"
     ]
    }
   ],
   "source": [
    "print(myarray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
