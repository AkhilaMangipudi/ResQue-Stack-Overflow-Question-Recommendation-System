{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "import csv\n",
    "#xmlfile = '../IR_datasets/datascience.stackexchange.com/PostLinks.xml'\n",
    "xmlfile = '../IR_datasets/biology.stackexchange.com/PostLinks.xml'\n",
    "tree = ET.parse(xmlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCSV(root,postlinksFile):\n",
    "    with open(postlinksFile,mode='w',encoding='utf-8') as postlinks:\n",
    "        postlinks = csv.writer(postlinks, delimiter=',')\n",
    "        postlinks.writerow(['Id','PostId','RelatedPostId','LinkTypeId'])\n",
    "        for row in root.findall('row'):\n",
    "            Id = row.get('Id')\n",
    "            postId = row.get('PostId')\n",
    "            relatedpostId = row.get('RelatedPostId')\n",
    "            linktypeId = row.get('LinkTypeId')\n",
    "            postlinks.writerow([Id,postId,relatedpostId,linktypeId])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "createCSV(root,\"../csv_files/postlinks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "postlinksDF = pd.read_csv('../csv_files/postlinks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(postlinksDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5292, 4)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postlinksDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#final list of dict to keep track of related post ids and answer ids for each question id\n",
    "postLinks = []\n",
    "#to keep track of questions that were already encountered\n",
    "posts = [] \n",
    "\n",
    "for index, row in postlinksDF.iterrows():\n",
    "    temp = {'postID': None,'relatedID': [],'answerID': [] } \n",
    "    temp['postID'] = row['PostId']\n",
    "    if(row['PostId'] in posts and len(posts)!=0):\n",
    "        for i in range(0,len(posts)):\n",
    "            if(row['PostId'] == postLinks[i]['postID']):\n",
    "                postLinks[i]['relatedID'].append(row[\"RelatedPostId\"])\n",
    "                postLinks[i]['answerID'].append(row[\"Id\"])\n",
    "    else:  \n",
    "        temp['relatedID'].append(row[\"RelatedPostId\"])\n",
    "        temp['answerID'].append(row[\"Id\"])   \n",
    "        posts.append(temp['postID'])\n",
    "        postLinks.append(temp)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3579"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(postLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#load the file of recommendations made by our model for each question\n",
    "\n",
    "#Normalised Datascience \n",
    "n_ds_onlytitle_recommended_que= pickle.load(open(\"../models/n_ds_onlytitle_ques_recommendations.dat\",\"rb\"))\n",
    "n_ds_withouttags_recommended_que= pickle.load(open(\"../models/n_ds_withouttags_ques_recommendations.dat\",\"rb\"))\n",
    "n_ds_withtags_recommended_que= pickle.load(open(\"../models/n_ds_withtags_ques_recommendations.dat\",\"rb\"))\n",
    "n_ds_ans = pickle.load(open(\"../models/n_ds_answers_recommendations.dat\",\"rb\"))\n",
    "\n",
    "#Normalised Biology\n",
    "n_bio_onlytitle_recommended_que= pickle.load(open(\"../models/n_bio_onlytitle_ques_recommendations.dat\",\"rb\"))\n",
    "n_bio_withouttags_recommended_que= pickle.load(open(\"../models/n_bio_withouttags_ques_recommendations.dat\",\"rb\"))\n",
    "n_bio_withtags_recommended_que= pickle.load(open(\"../models/n_bio_withtags_ques_recommendations.dat\",\"rb\"))\n",
    "n_bio_ans = pickle.load(open(\"../models/n_bio_answers_recommendations.dat\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalised Biology Combined (Q+A)\n",
    "bio_combined_onlytitle= pickle.load(open(\"../models/bio_que_ans_onlytitle_recommendations.dat\",\"rb\"))\n",
    "bio_combined_withouttags= pickle.load(open(\"../models/bio_que_ans_withouttags_recommendations.dat\",\"rb\"))\n",
    "bio_combined_withtags= pickle.load(open(\"../models/bio_que_ans_withtags_recommendations.dat\",\"rb\"))\n",
    "\n",
    "#Normalised Data Science Combined (Q+A)\n",
    "ds_combined_onlytitle= pickle.load(open(\"../models/ds_que_ans_onlytitle_recommendations.dat\",\"rb\"))\n",
    "ds_combined_withouttags= pickle.load(open(\"../models/ds_que_ans_withouttags_recommendations.dat\",\"rb\"))\n",
    "ds_combined_withtags= pickle.load(open(\"../models/ds_que_ans_withtags_recommendations.dat\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to evaluate recommendations for a question\n",
    "#Evaluation made against the questions present in PostLinks.xml\n",
    "#Weighted average of the number of questions from relatedID list are present in the list of recommendations \n",
    "#and the number of questions from relatedID list that are present in the top half of the list of recommendations\n",
    "\n",
    "def evaluate(recommended,n):\n",
    "    #print(len(recommended))\n",
    "    score  = 0\n",
    "    for i in range(0,len(postLinks)):\n",
    "        present = 0 \n",
    "        top = 0\n",
    "        count = len(postLinks[i]['relatedID'])\n",
    "        if postLinks[i]['postID'] in recommended.keys():\n",
    "            idx = 0\n",
    "            for rec in recommended[postLinks[i]['postID']][0:n]:\n",
    "                #print(rec)\n",
    "                idx+=1\n",
    "                if rec[0] in postLinks[i]['relatedID']:\n",
    "                    present+=1\n",
    "                    if (idx >= int(len(postLinks[i]['relatedID'])/2)):\n",
    "                        top+=1\n",
    "            if(present):\n",
    "                score+= (0.3* (present/count)+ 0.7*(top/present))\n",
    "    return (score/len(postLinks))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07424882629107982\n",
      "0.07397887323943661\n",
      "0.13045606975184434\n",
      "0.07032863849765258\n",
      "0.09507042253521122\n",
      "0.13252347417840366\n",
      "0.11089201877934265\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(n_ds_onlytitle_recommended_que,30))\n",
    "print(evaluate(n_ds_withouttags_recommended_que,30))\n",
    "print(evaluate(n_ds_withtags_recommended_que,30))\n",
    "print(evaluate(n_ds_ans,30))\n",
    "\n",
    "print(evaluate(ds_combined_onlytitle,30))\n",
    "print(evaluate(ds_combined_withtags,30))\n",
    "print(evaluate(ds_combined_withouttags,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09297658962998455\n",
      "0.13828856158277827\n",
      "0.18910027408560573\n",
      "0.1340232374033718\n",
      "0.18438134488218347\n",
      "0.19836569805346027\n",
      "0.22919600447052285\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(n_bio_onlytitle_recommended_que,30))\n",
    "print(evaluate(n_bio_withouttags_recommended_que,30))\n",
    "print(evaluate(n_bio_withtags_recommended_que,30))\n",
    "print(evaluate(n_bio_ans,30))\n",
    "\n",
    "print(evaluate(bio_combined_onlytitle,30))\n",
    "print(evaluate(bio_combined_withouttags,30))\n",
    "print(evaluate(bio_combined_withtags,30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
